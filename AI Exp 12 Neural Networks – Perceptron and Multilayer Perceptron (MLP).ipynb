{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNq+F7lPeg88xGUXxxrv2EX"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Task 1: Perceptron for AND Gate"],"metadata":{"id":"0HVB2OUyS32Y"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"zgq_jBkbMO-F"},"outputs":[],"source":["import numpy as np\n","\n","# Define training data for AND gate\n","X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n","y = np.array([0, 0, 0, 1])  # AND gate output\n"]},{"cell_type":"code","source":["# Initialize weights and bias\n","weights = np.zeros(2)\n","bias = 0\n","lr = 0.1\n","epochs = 10\n","\n","# Training loop\n","for epoch in range(epochs):\n","    for i in range(len(X)):\n","        linear_output = np.dot(X[i], weights) + bias\n","        prediction = 1 if linear_output >= 0 else 0\n","        error = y[i] - prediction\n","        weights += lr * error * X[i]\n","        bias += lr * error\n","    print(f\"Epoch {epoch+1} - Weights: {weights}, Bias: {bias}\")\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9Jpmn14NS6sl","executionInfo":{"status":"ok","timestamp":1753173881511,"user_tz":-360,"elapsed":22,"user":{"displayName":"Alimul Rajee","userId":"01282216439520979768"}},"outputId":"a800ab79-0946-480c-9bb2-ee4535406be5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 - Weights: [0.1 0.1], Bias: 0.0\n","Epoch 2 - Weights: [0.2 0.1], Bias: -0.1\n","Epoch 3 - Weights: [0.2 0.1], Bias: -0.20000000000000004\n","Epoch 4 - Weights: [0.2 0.1], Bias: -0.20000000000000004\n","Epoch 5 - Weights: [0.2 0.1], Bias: -0.20000000000000004\n","Epoch 6 - Weights: [0.2 0.1], Bias: -0.20000000000000004\n","Epoch 7 - Weights: [0.2 0.1], Bias: -0.20000000000000004\n","Epoch 8 - Weights: [0.2 0.1], Bias: -0.20000000000000004\n","Epoch 9 - Weights: [0.2 0.1], Bias: -0.20000000000000004\n","Epoch 10 - Weights: [0.2 0.1], Bias: -0.20000000000000004\n"]}]},{"cell_type":"code","source":["# Test output\n","for input_val in X:\n","    result = 1 if np.dot(input_val, weights) + bias >= 0 else 0\n","    print(f\"Input: {input_val} => Predicted: {result}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ldPBFyrHToQP","executionInfo":{"status":"ok","timestamp":1753173922759,"user_tz":-360,"elapsed":27,"user":{"displayName":"Alimul Rajee","userId":"01282216439520979768"}},"outputId":"6612eec5-7ad9-4759-8268-9a2e1ec69c9f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input: [0 0] => Predicted: 0\n","Input: [0 1] => Predicted: 0\n","Input: [1 0] => Predicted: 0\n","Input: [1 1] => Predicted: 1\n"]}]},{"cell_type":"markdown","source":["Task 2: Multilayer Perceptron for MNIST using PyTorch"],"metadata":{"id":"20s82A_NTg5k"}},{"cell_type":"code","source":["import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","# Device setup\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Download and preprocess MNIST dataset\n","transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n","train_set = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n","test_set = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n","\n","train_loader = torch.utils.data.DataLoader(train_set, batch_size=64, shuffle=True)\n","test_loader = torch.utils.data.DataLoader(test_set, batch_size=1000, shuffle=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5iYLTcx5T4Ny","executionInfo":{"status":"ok","timestamp":1753173985628,"user_tz":-360,"elapsed":14349,"user":{"displayName":"Alimul Rajee","userId":"01282216439520979768"}},"outputId":"043ec6a8-a381-4b50-d6ed-7d18b8dd77ad"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:00<00:00, 21.9MB/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 619kB/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:00<00:00, 5.70MB/s]\n","100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 1.82MB/s]\n"]}]},{"cell_type":"code","source":["# Define MLP Model\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super(MLP, self).__init__()\n","        self.fc1 = nn.Linear(28*28, 128)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 10)\n","\n","    def forward(self, x):\n","        x = x.view(-1, 28*28)\n","        x = self.relu(self.fc1(x))\n","        return self.fc2(x)\n","\n","model = MLP().to(device)\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n"],"metadata":{"id":"WtWAxOT0T4vV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training loop\n","for epoch in range(5):\n","    for images, labels in train_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        loss = criterion(outputs, labels)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","    print(f\"Epoch {epoch+1} Loss: {loss.item():.4f}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vq78ZvbsUA-8","executionInfo":{"status":"ok","timestamp":1753174088869,"user_tz":-360,"elapsed":78997,"user":{"displayName":"Alimul Rajee","userId":"01282216439520979768"}},"outputId":"f4465e42-b3a4-43cf-c782-b5fcfe1a7fd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1 Loss: 0.3457\n","Epoch 2 Loss: 0.0902\n","Epoch 3 Loss: 0.1284\n","Epoch 4 Loss: 0.0313\n","Epoch 5 Loss: 0.1448\n"]}]},{"cell_type":"code","source":["print(outputs.shape)\n","print(labels.shape)\n","print(model)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P9c6Hci9Uwkg","executionInfo":{"status":"ok","timestamp":1753174269459,"user_tz":-360,"elapsed":16,"user":{"displayName":"Alimul Rajee","userId":"01282216439520979768"}},"outputId":"e0482494-5720-477b-d3fa-50e648c39256"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1000, 10])\n","torch.Size([1000])\n","MLP(\n","  (fc1): Linear(in_features=784, out_features=128, bias=True)\n","  (relu): ReLU()\n","  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",")\n"]}]},{"cell_type":"code","source":["# Testing accuracy\n","correct, total = 0, 0\n","with torch.no_grad():\n","    for images, labels in test_loader:\n","        images, labels = images.to(device), labels.to(device)\n","        outputs = model(images)\n","        _, predicted = torch.max(outputs.data, 1)\n","        total += labels.size(0)\n","        correct += (predicted == labels).sum().item()\n","\n","print(f\"ðŸŽ¯ Test Accuracy: {(correct / total) * 100:.2f}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lDBpl42jUDIh","executionInfo":{"status":"ok","timestamp":1753174134766,"user_tz":-360,"elapsed":5030,"user":{"displayName":"Alimul Rajee","userId":"01282216439520979768"}},"outputId":"21108dbf-313b-41c1-af9b-90159d60f5c5"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["ðŸŽ¯ Test Accuracy: 96.07%\n"]}]},{"cell_type":"code","source":["# âœ… Install necessary libraries\n","!pip install torch torchvision scikit-learn --quiet\n","\n","# âœ… Import required libraries\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.datasets import make_classification, load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler\n","import numpy as np\n","\n","# âœ… Task 1: Single-layer Perceptron for Binary Classification\n","# Generate synthetic dataset\n","X, y = make_classification(n_samples=200, n_features=2, n_classes=2, n_informative=2, n_redundant=0, random_state=1)\n","X = StandardScaler().fit_transform(X)\n","\n","# Convert to PyTorch tensors\n","X_tensor = torch.tensor(X, dtype=torch.float32)\n","y_tensor = torch.tensor(y.reshape(-1, 1), dtype=torch.float32)\n","\n","# Define Perceptron model\n","class Perceptron(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc = nn.Linear(2, 1)  # 2 input features, 1 output\n","\n","    def forward(self, x):\n","        return torch.sigmoid(self.fc(x))\n","\n","model = Perceptron()\n","criterion = nn.BCELoss()\n","optimizer = optim.SGD(model.parameters(), lr=0.1)\n","\n","# Train the model\n","for epoch in range(100):\n","    optimizer.zero_grad()\n","    outputs = model(X_tensor)\n","    loss = criterion(outputs, y_tensor)\n","    loss.backward()\n","    optimizer.step()\n","    if epoch % 10 == 0:\n","        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n","\n","# âœ… Task 2: MLP on Iris Dataset\n","# Load and prepare the Iris dataset\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","\n","X = StandardScaler().fit_transform(X)\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Convert to tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n","\n","# Define MLP model\n","class MLP(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","        self.fc1 = nn.Linear(4, 10)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(10, 3)  # 3 output classes\n","\n","    def forward(self, x):\n","        x = self.relu(self.fc1(x))\n","        return self.fc2(x)\n","\n","mlp_model = MLP()\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(mlp_model.parameters(), lr=0.01)\n","\n","# Train the MLP\n","for epoch in range(100):\n","    optimizer.zero_grad()\n","    outputs = mlp_model(X_train_tensor)\n","    loss = criterion(outputs, y_train_tensor)\n","    loss.backward()\n","    optimizer.step()\n","    if epoch % 10 == 0:\n","        print(f\"Epoch {epoch}: Loss = {loss.item():.4f}\")\n","\n","# Evaluate the model\n","with torch.no_grad():\n","    test_preds = mlp_model(X_test_tensor)\n","    predicted_classes = torch.argmax(test_preds, dim=1)\n","    accuracy = (predicted_classes == y_test_tensor).float().mean()\n","    print(f\"\\nâœ… Test Accuracy: {accuracy.item()*100:.2f}%\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kwXHDR37lSqw","executionInfo":{"status":"ok","timestamp":1753178668763,"user_tz":-360,"elapsed":112925,"user":{"displayName":"Alimul Rajee","userId":"01282216439520979768"}},"outputId":"b55f728c-d65c-4fad-98ef-5db4b5fc8e0c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m66.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hEpoch 0: Loss = 0.8636\n","Epoch 10: Loss = 0.6980\n","Epoch 20: Loss = 0.5971\n","Epoch 30: Loss = 0.5341\n","Epoch 40: Loss = 0.4928\n","Epoch 50: Loss = 0.4642\n","Epoch 60: Loss = 0.4435\n","Epoch 70: Loss = 0.4279\n","Epoch 80: Loss = 0.4158\n","Epoch 90: Loss = 0.4062\n","Epoch 0: Loss = 1.1485\n","Epoch 10: Loss = 0.8006\n","Epoch 20: Loss = 0.5458\n","Epoch 30: Loss = 0.4020\n","Epoch 40: Loss = 0.3139\n","Epoch 50: Loss = 0.2543\n","Epoch 60: Loss = 0.2072\n","Epoch 70: Loss = 0.1701\n","Epoch 80: Loss = 0.1419\n","Epoch 90: Loss = 0.1206\n","\n","âœ… Test Accuracy: 100.00%\n"]}]}]}